---
title: ""
author: ""
date: ""
header-includes:
   - \usepackage{bbm}
output: pdf_document
---

```{r setup, include=FALSE}
# By default, the code chunks are hidden for brevity. Set the echo argument to TRUE for blocks you want to share the code in the output for. 
knitr::opts_chunk$set(echo = F, warning = F)
```

```{r packages and data, message=FALSE}
# Load packages and data to be clear from the start
library(tidyverse)
library(brms)
library(here)
```

<!-- 
The text surrounded by these arrows is for your information and is hidden when the final document is knitted.
-->

## Study Information

### 1.	Title 

<!-- 
Provide the working title of your study. It may be the same title that you submit for publication of your final manuscript, but it is not a requirement.

Example: Effect of sugar on brownie tastiness. 

More info: The title should be a specific and informative description of a project. Vague titles such as 'Fruit fly preregistration plan' are not appropriate.
-->

Testing the influence of question-under-discussion (QUD) on the interpretation
of "if" as "if and only if" (Follow-up experiment)

### 2.	Authorship

<!--
List authors and affiliations as applicable. Placing a number or letter in upward arrows, (e.g. ^2^) creates a superscript
--> 

Britta Grusdt^1^ 
Mingya Liu^2^
Michael Franke^3^

^1^ Osnabrück University
^2^ Humboldt-Universität zu Berlin
^3^ University of Tübingen

### 3. Description

<!--
Please give a brief description of your study, including some background, the purpose of the of the study, or broad research questions. 

Example: Though there is strong evidence to suggest that sugar affects taste preferences, the effect has never been demonstrated in brownies. Therefore, we will measure taste preference for four different levels of sugar concentration in a standard brownie recipe to determine if the effect exists in this pastry. 

More info: The description should be no longer than the length of an abstract. It can give some context for the proposed study, but great detail is not needed here for your preregistration. 
-->

Many conditionals in natural language (expressions of the form 'if p, then q')
tend to be interpreted as biconditionals ('if *and only if p*, then q'), that
is, the antecedent p is considered the single possible cause of the consequent
q. However, there is no consensus about the factors that elicit a biconditional
interpretation of a conditional.

Von Fintel (2001) proposed that a biconditional reading of a conditional is
triggered if the conditional is considered as *exhaustive* list of sufficient
conditions that bring about the consequent. He argued that this is expected to
be the case when the conditional is considered an answer to a (possibly
implicit) question-under-discussion (QUD) which requires the answer to be an
exhaustive list of suffucient conditions, e.g. when QUD = "under which
conditions will q occur?" Since the conditional 'if p, q' mentions only one such
condition, namely p, it is perfected and thus interpreted as biconditional.
Contrary to that, the conditional, 'if p, q', is hypothesized not to be
interpreted as biconditional when the QUD requires an exhaustive list of
*consequences of p*, e.g. when QUD = "what follows from p?".

### 4.	Hypotheses

<!-- 
List specific, concise, and testable hypotheses. Please state if the hypotheses are directional or non-directional. If directional, state the direction. A predicted effect is also appropriate here. If a specific interaction or moderation is important to your research, you can list that as a separate hypothesis. 

Example: If taste affects preference, then mean preference indices will be higher with higher concentrations of sugar. 
-->
With the present experiment we aim to test whether there is a QUD-effect on the
occurrence of conditional perfection according to the theory described in 3. To
this end, we use a picture selection task where participants read a dialogue
between Ann and Bob where Ann asks a question (the QUD) and Bob replies with a
conditional.  Ann's question is about a scene of block arrangements that she
sees partly, but Bob sees the entire scene. Participants are asked to select one
or more of three shown pictures of block arrangements that they think Ann and
Bob see (Bob completely, Ann partially) and that Bob's utterance is based on.
One of the pictures shows an exhaustive situation, i.e. a situation that shows a
single possible reason for the consequent (mentioned in Bob's conditional) to
occur (corresponding to a biconditional interpretation), another picture shows a
non-exhaustive situation, i.e. a situation where two possible reasons are
conceivable for why the consequent may occur (corresponding to a
non-biconditional interpretation) and the third picture shows a scene that is
incompatible with Bob's response (referred to as control scene).

We expect QUD='will-q' to trigger a CP-reading more than QUD='if-p' does. That
is, we expect participants to interpret the conditional more exhaustively when
QUD=will-q as compared to when QUD=if-p (**main hypothesis**); the selection of
only the non-exhaustive situation corresponds to a non-exhaustive
interpretation, the selection of only the exhaustive situation corresponds to an
exhaustive interpretation whereas the selection of both, the exhaustive and the
non-exhaustive situation, allows an exhaustive as well as a non-exhaustive
interpretation.

More concretely, we expect the selection rate for only the exhaustive situation
to be larger when QUD='will-q' than when QUD='if-p'(**H1.1**). On the other hand,
we expect the selection rate for both, the exhaustive and the non-exhaustive
situation, to be larger when QUD='if-p' than when QUD='will-q' (**H1.2**).

These hypotheses can only be tested for data from stimuli B+D since there are no
trials with stimuli A+C where QUD=will-q (see Section 'Design Plan').


## Design Plan

<!-- 
In this section, you will be asked to describe the overall design of your study. Remember that this research plan is designed to register a single study, so if you have multiple experimental designs, please complete a separate preregistration. 
-->

Within-subject design: each participant sees each manipulation once.

4 critical stimuli, each of which shows an exhaustive, a non-exhaustive and a
control scene (in random order for each trial + participant). Stimuli A+C are
shown once with QUD=if-p, stimuli B+D twice, once with QUD=if-p and once with
QUD=will-q. For stimuli A and B, the distractor (yellow block) is absent in the
exhaustive situation whereas it is present in the exhaustive situation of
stimuli C and D. Further, in the non-exhaustive situation of stimuli A and C,
the second cause for the lower block to fall is because of its own position
(internal cause) whereas in stimuli B and D, the second possible reason for the
lower block to fall in the non-exhaustive situation is because a third block
(yellow block) may fall that would make the lower block fall as well (external
cause).

![The two relevant pictures shown in critical trials (stimuli A-D)](/Users/brittagr/PhD/ConditionalPerfection/paper/figs/follow-up-4-critical.png)

*Training phase* (8 trials):

Participants see animations of block arrangements. Before they can start the
animation, we ask them to indicate (by clicking on buttons) which blocks they
think will fall, where multiple selections or the selection of 'none',
referring to 'no block will fall', are possible. After they saw which blocks
fell in the animation, they get feedback about their choice and learn which
blocks actually fell. The training trials are identical to those from Experiment
1 plus one additional trial where participants see the scene that is used as
control scene in the test phase.

*Test phase* 17 trials (1 attention-check + 6 critical + 4 practice + 6 filler):

Participants see Ann's screen with a partial scene and Bob's screen with a
question mark. Participants have to click on three buttons, the first button
reveals Ann's question (the QUD) written in bold face, the second Bob's response
to Ann's question and the third reveals three scenes, an exhaustive, a
non-exhaustive and a control scene (shown in random order for each participant
and trial) with the following written above the three pictures: 'Please select
the picture(s) that you think Ann and Bob are talking about.'. Participants are
asked to make a selection by clicking on the respective picture(s).


### 5.	Study Type 

<!-- 
Delete all that do not apply.-->

- Experiment - A researcher randomly assigns treatments to study subjects, this
includes field or lab experiments. This is also known as an intervention
experiment and includes randomized controlled trials.

<!-- 
Observational Study - Data is collected from study subjects that are not randomly assigned to a treatment. This includes surveys, natural experiments, and regression discontinuity designs.
-->

<!-- - Meta-Analysis - A systematic review of published studies.


- Other (explain your study type)
-->

### 6.	Blinding

<!-- 
Blinding describes who is aware of the experimental manipulations within a study. Delete all that do not apply. 
-->

- For studies that involve human subjects, they will not know the treatment
group to which they have been assigned.

<!--
- Personnel who interact directly with the study subjects (either human or non-human subjects) will not be aware of the assigned treatments. (Commonly known as “double blind”).

- Personnel who analyze the data collected from the study are not aware of the treatment applied to any given group.
-->

### 7.	Is there any additional blinding in this study?

<!-- 
Describe any additional blinding procedures that were not covered by the options above. 
-->

Participants are blind to the purpose of the experiment. Being an online study,
there is no direct interaction with an experimenter.

### 8.	Study design

<!-- 
Describe your study design. Examples include two-group, factorial, randomized block, and repeated measures. Is it a between (unpaired), within-subject (paired), or mixed design? Describe any counterbalancing required. Typical study designs for observation studies include cohort, cross sectional, and case-control studies.

Example: We have a between subjects design with 1 factor (sugar by mass) with 4 levels. 

More info: This question has a variety of possible answers. The key is for a researcher to be as detailed as is necessary given the specifics of their design. Be careful to determine if every parameter has been specified in the description of the study design. There may be some overlap between this question and the following questions. That is OK, as long as sufficient detail is given in one of the areas to provide all of the requested information. For example, if the study design describes a complete factorial, 2 X 3 design and the treatments and levels are specified previously, you do not have to repeat that information. 
-->

We use a within subjects design with 3 factors (QUD x exhaustive x
non-exhaustive) with 2 levels each:

  * QUD: if-p, will-q
  * exh: with distractor (withD), without distractor (woD)
  * nonExh: external (ext), internal (int)

Note that the 2 combinations of QUD:will-q with stimulus A (<exh:woD,
**nonExh:int**>) and stimulus C (<exh:withD, **nonExh:int**>) are excluded due
to the setup of the experiment: when QUD:will-q, the consequent-block must be at
the same position in the exhaustive and non-exhaustive situation since when
QUD:will-q, the non-occluded part that Ann sees contains the consequent-block
and each of the three pictures among which participants select (exhaustive,
non-exhaustive, control) needs to be compatible with the partial scene that Ann
sees.


### 9.	Randomization

<!-- 
If you are doing a randomized study, how will you randomize, and at what level?

Example: We will use block randomization, where each participant will be randomly assigned to one of the four equally sized, predetermined blocks. The random number list used to create these four blocks will be created using the web applications available at http://random.org. 

More info: Typical randomization techniques include: simple, block, stratified, and adaptive covariate randomization. If randomization is required for the study, the method should be specified here, not simply the source of random numbers.
-->

Test trials comprise 6 critical, 6 filler, 4 practice and 1 attention check
trial.
The first 4 trials are the 4 practice trials, randomly shuffled for each
participant. Subsequent trials alternate between filler and control trials and
the attention check trial follows the third control trial. The order of trials
within filler and critical trials was randomized for each participant.
For each participant the color of the antecedent- and the consequent block (one
blue, the other green) is randomly assigned in each test trial. The order of the
three shown pictures is randomly assigned for each participant in each trial.

## Sampling Plan 

<!-- 
In this section we’ll ask you to describe how you plan to collect samples, as well as the number of samples you plan to collect and your rationale for this decision. Please keep in mind that the data described in this section should be the actual data used for analysis, so if you are using a subset of a larger dataset, please describe the subset that will actually be used in your study. 
-->

### 10. Existing data

<!-- 
Preregistration is designed to make clear the distinction between confirmatory tests, specified prior to seeing the data, and exploratory analyses conducted after observing the data. Therefore, creating a research plan in which existing data will be used presents unique challenges. Please select the description that best describes your situation. Please do not hesitate to contact the COS if you have questions about how to answer this question (prereg@cos.io). 

Delete all that do not apply. 

- Registration prior to creation of data: As of the date of submission of this research plan for preregistration, the data have not yet been collected, created, or realized. 
-->

Registration prior to any human observation of the data.
<!--As of the date of submission, the data exist but have not yet been quantified, constructed, observed, or reported by anyone - including individuals that are not associated with the proposed study. Examples include museum specimens that have not been measured and data that have been collected by non-human collectors and are inaccessible.-->

<!--
- Registration prior to accessing the data: As of the date of submission, the data exist, but have not been accessed by you or your collaborators. Commonly, this includes data that has been collected by another researcher or institution.

- Registration prior to analysis of the data: As of the date of submission, the data exist and you have accessed it, though no analysis has been conducted related to the research plan (including calculation of summary statistics). A common situation for this scenario when a large dataset exists that is used for many different studies over time, or when a data set is randomly split into a sample for exploratory analyses, and the other section of data is reserved for later confirmatory data analysis.

- Registration following analysis of the data: As of the date of submission, you have accessed and analyzed some of the data relevant to the research plan. This includes preliminary analysis of variables, calculation of descriptive statistics, and observation of data distributions. Please see cos.io/prereg for more information. 
-->

### 11.	Explanation of existing data

<!-- 
If you indicate that you will be using some data that already exist in this study, please describe the steps you have taken to assure that you are unaware of any patterns or summary statistics in the data. This may include an explanation of how access to the data has been limited, who has observed the data, or how you have avoided observing any analysis of the specific data you will use in your study. 

Example: An appropriate instance of using existing data would be collecting a sample size much larger than is required for the study, using a small portion of it to conduct exploratory analysis, and then registering one particular analysis that showed promising results. After registration, conduct the specified analysis on that part of the dataset that had not been investigated by the researcher up to that point. 

More info: An appropriate instance of using existing data would be collecting a sample size much larger than is required for the study, using a small portion of it to conduct exploratory analysis, and then registering one particular analysis that showed promising results. After registration, conduct the specified analysis on that part of the dataset that had not been investigated by the researcher up to that point. 
-->

The  data was collected prior to finalizing the preregistration report, but no
person involved has inspected the data other than for evaluating the attention
checks, which is a necessary part of the data collection.

### 12.	Data collection procedures

<!-- 
Please describe the process by which you will collect your data. If you are using human subjects, this should include the population from which you obtain subjects, recruitment efforts, payment for participation, how subjects will be selected for eligibility from the initial pool (e.g. inclusion and exclusion rules), and your study timeline. For studies that donÍt include human subjects, include information about how you will collect samples, duration of data gathering efforts, source or location of samples, or batch numbers you will use. 

Example: Participants will be recruited through advertisements at local pastry shops. Participants will be paid $10 for agreeing to participate (raised to $30 if our sample size is not reached within 15 days of beginning recruitment). Participants must be at least 18 years old and be able to eat the ingredients of the pastries.

More information: The answer to this question requires a specific set of instructions so that another person could repeat the data collection procedures and recreate the study population. Alternatively, if the study population would be unable to be reproduced because it relies on a specific set of circumstances unlikely to be recreated (e.g., a community of people from a specific time and location), the criteria and methods for creating the group and the rationale for this unique set of subjects should be clear. 
--> 

Participants are recruited via the online Platform Prolific, they get paid 1.30
pounds for their participation. To be eligible for participation, one must be at
least 18 years old and a native speaker of English (self-reported), have a
minimal approval rate on Prolific of 80% and must not have taken part in any of
our previous studies with similar stimuli.


### 13.	Sample size

<!-- 
Describe the sample size of your study. How many units will be analyzed in the study? This could be the number of people, birds, classrooms, plots, interactions, or countries included. If the units are not individuals, then describe the size requirements for each unit. If you are using a clustered or multilevel design, how many units are you collecting at each level of the analysis?

Example: Our target sample size is 280 participants. We will attempt to recruit up to 320, assuming that not all will complete the total task. 

More information: For some studies, this will simply be the number of samples or the number of clusters. For others, this could be an expected range, minimum, or maximum number. 
-->

Due to funding restrictions, we collect data from a total of 215 participants. 

### 14. Sample size rationale 

<!-- 
This could include a power analysis or an arbitrary constraint such as time, money, or personnel.

Example: We used the software program G*Power to conduct a power analysis. Our goal was to obtain .95 power to detect a medium effect size of .25 at the standard .05 alpha error probability. 

More information: This gives you an opportunity to specifically state how the sample size will be determined. A wide range of possible answers is acceptable; remember that transparency is more important than principled justifications. If you state any reason for a sample size upfront, it is better than stating no reason and leaving the reader to “fill in the blanks.” Acceptable rationales include: a power analysis, an arbitrary number of subjects, or a number based on time or monetary constraints. 
-->

We want to recruit the maximal number of participants allowed by our funding
situation. Given our stipulated payment, these are 215 participants in total.

### 15. Stopping rule 

<!-- 
If your data collection procedures do not give you full control over your exact sample size, specify how you will decide when to terminate your data collection. 

Example: We will post participant sign-up slots by week on the preceding Friday night, with 20 spots posted per week. We will post 20 new slots each week if, on that Friday night, we are below 320 participants. 

More information: You may specify a stopping rule based on p-values only in the specific case of sequential analyses with pre-specified checkpoints, alphas levels, and stopping rules. Unacceptable rationales include stopping based on p-values if checkpoints and stopping rules are not specified. If you have control over your sample size, then including a stopping rule is not necessary, though it must be clear in this question or a previous question how an exact sample size is attained. 
-->

This is not applicable. 

## Variables 

<!-- 
In this section you can describe all variables (both manipulated and measured variables) that will later be used in your confirmatory analysis plan. In your analysis plan, you will have the opportunity to describe how each variable will be used. If you have variables which you are measuring for exploratory analyses, you are not required to list them, though you are permitted to do so. 
-->

### 16. Manipulated variables

<!-- 
Describe all variables you plan to manipulate and the levels or treatment arms of each variable. This is not applicable to any observational study. 

Example: We manipulated the percentage of sugar by mass added to brownies. The four levels of this categorical variable are: 15%, 20%, 25%, or 40% cane sugar by mass. 

More information: For any experimental manipulation, you should give a precise definition of each manipulated variable. This must include a precise description of the levels at which each variable will be set, or a specific definition for each categorical treatment. For example, “loud or quiet,” should instead give either a precise decibel level or a means of recreating each level. 'Presence/absence' or 'positive/negative' is an acceptable description if the variable is precisely described.
-->

1. We manipulate which exhaustive and which non-exhaustive situation is shown as
pair in a trial, together with a third situation, the control scene (which
contradicts Bob's response and is always the same).

  1.1 Each **non-exhaustive** situation can be realized either as *external* or
  *internal*:
  
  * In an *external*, non-exhaustive situation the consequent-block may fall
    because of a third block positioned on the edge (yellow block in upper right
    of picture).
  * In an *internal*, non-exhaustive situation the consequent-block may fall
    because of its own position, on the edge of its base platform (when
    non-exhaustive:external the consequent-block is positioned completely on the
    platform).
  
  1.2 Each **exhaustive** situation can be realized either as *with distractor* or
  *without distractor*:
  
  * In a exhaustive situation *with distractor*, there is an additional yellow
    block on a platform in the upper right corner which lies horizontally centered
    on the platform such that it is completely on top of the platform and has no
    influence on the falling of the other blocks.
  * In an exhaustive situation *without distractor* there is no such yellow
    distractor block.

2. We manipulate the **QUD** shown in each trial, as encoded by Ann's question,
which has one of the following two levels:
  * "What happens if the antecedent-block falls?" (if-p)
  * "Will the consequent-block fall?" (will-q) 
where 'antecedent-block' and 'consequent-block' are replaced by the respectively
corresponding color (in upper case letters), e.g. '... the GREEN block ...'

Since the consequent-block in the *internal* non-exhaustive situation has a
different position (on the edge of the platform) than the consequent has in both
exhaustive situations (completely on platform), this situation cannot be used in
combination with the QUD *will-q* (See note in 8.). Therefore, we have 2
critical trials less, i.e. 2 (exhaustive situations) x 2 (non-exhaustive
situations) x 2 (QUDs) - 2 = 6 critical trials.

### 17. Measured variables 

<!-- 
Describe each variable that you will measure. This will include outcome measures, as well as any predictors or covariates that you will measure. You do not need to include any variables that you plan on collecting if they are not going to be included in the confirmatory analyses of this study.

Example: The single outcome variable will be the perceived tastiness of the single brownie each participant will eat. We will measure this by asking participants ‘How much did you enjoy eating the brownie’ (on a scale of 1-7, 1 being ‘not at all’, 7 being ‘a great deal’) and ‘How good did the brownie taste’ (on a scale of 1-7, 1 being ‘very bad’, 7 being ‘very good’). 

More information: Observational studies and meta-analyses will include only measured variables. As with the previous questions, the answers here must be precise. For example, 'intelligence,' 'accuracy,' 'aggression,' and 'color' are too vague. Acceptable alternatives could be 'IQ as measured by Wechsler Adult Intelligence Scale' 'percent correct,' 'number of threat displays,' and 'percent reflectance at 400 nm.'
-->

The single dependent variable that we measure is the set of pictures that
participants select in each test trial. Theoretically, all 7 combinations of at
least one selected picture are possible. However, only the following 3
combinations of selected situations are relevant: 

  1. only non-exhaustive
  2. exhaustive + non-exhaustive
  3. only exhaustive

Measured predictors are the manipulated variables 'QUD', 'exh' and 'nonExh' as
described in 16.

Besides the data recorded in the test trials, participants are asked the
following questions in the end of the experiment:

During the experiment, **Ann's question** was ...

  * always the same
  * sometimes about what happened if one block fell.
  * sometimes about the yellow block.
  * sometimes about whether one block would fall.
  * sometimes about several blocks at a time.
  
  * I only read Bob's answer.
  
Most of the time I selected a **single picture** ....

  * even though another picture wasn't unlikely either.
  * only when I was very confident about my decision.

We ask them to check all of the statements that they agree with.

### 18. Indices 

<!-- 
If any measurements are  going to be combined into an index (or even a mean), what measures will you use and how will they be combined? Include either a formula or a precise description of your method. If your are using a more complicated statistical method to combine measures (e.g. a factor analysis), you can note that here but describe the exact method in the analysis plan section.

Example: We will take the mean of the two questions above to create a single measure of ‘brownie enjoyment.’ 

More information: If you are using multiple pieces of data to construct a single variable, how will this occur? Both the data that are included and the formula or weights for each measure must be specified. Standard summary statistics, such as “means” do not require a formula, though more complicated indices require either the exact formula or, if it is an established index in the field, the index must be unambiguously defined. For example, “biodiversity index” is too broad, whereas “Shannon’s biodiversity index” is appropriate. 
-->

We will use participants' categorical selection of pictures (e.g., exhaustive +
non-exhaustive situation) and consider the selection rates of each possible
combination of selected pictures as the proportion of participants who selected
the respective combination (per QUD and stimulus).

## Analysis Plan

<!-- 
You may describe one or more confirmatory analysis in this preregistration. Please remember that all analyses specified below must be reported in the final article, and any additional analyses must be noted as exploratory or hypothesis generating.

A confirmatory analysis plan must state up front which variables are predictors (independent) and which are the outcomes (dependent), otherwise it is an exploratory analysis. You are allowed to describe any exploratory work here, but a clear confirmatory analysis is required. 
-->

* Independent variables: QUD, exhaustive (exh), nonExhaustive (nonExh)
* Dependent variables: selected combination of pictures 

We abbreviate the (relevant) combinations of selected pictures like so:

  - exhaustive and non-exhaustive: 'both'
  - only exhaustive: 'exh'
  - only non-exhaustive: 'nonExh'

Our main hypotheses are the following:

- **Main hypothesis**: We hypothesize that there is a QUD-effect on the
occurrence of conditional perfection in the sense that we expect participants to
prefer an exhaustive interpretation of the conditional when QUD=will-q as
compared to QUD=if-p. We consider the three relevant response categories to
reflect the degree of how exhaustive the conditional is interpreted where the
selection of only the non-exhaustive situation is at the lower extreme (not
interpreted exhaustively) and the selection of only the exhaustive situation is
at the upper extreme (interpreted exhaustively) and the selection of both, the
exhaustive and the non-exhaustive situation, is in between both extremes.

Further, we will test the following two, slightly more specific hypotheses:
  
- **H1.1**: We expect to see a preference for the exhaustive interpretation of
the conditional, corresponding to the selection of only the exhaustive
situation, in trials where QUD=will-q as compared to trials where QUD=if-p.
More concretely, we expect the selection rate of the exhaustive situation to be
larger when QUD=will-q as compared to when QUD=if-p: 
P(exh | QUD = will-q) > P(exh | QUD = if-p).

- **H1.2**: We expect the selection rate of choosing both situations
(exh+nonExh) to be larger when QUD=if-p as compared to when QUD=will-q:
P(both | QUD = will-q) < P(both | QUD = if-p).


### 19. Statistical models

<!-- 
What statistical model will you use to test each hypothesis? Please include the type of model (e.g. ANOVA, multiple regression, SEM, etc) and the specification of the model (this includes each variable that will be included as predictors, outcomes, or covariates). Please specify any interactions, subgroup analyses, pairwise or complex controls, or follow-up tests from omnibus tests. If you plan on using any positive controls, negative controls, or manipulation checks you may mention that here. Remember that any test not included here must be noted as an exploratory test in your final article. 

Example:  We will use a one-way between subjects ANOVA to analyze our results. The manipulated, categorical independent variable is 'sugar' whereas the dependent variable is our taste index. 

More information: This is perhaps the most important and most complicated question within the preregistration. As with all of the other questions, the key is to provide a specific recipe for analyzing the collected data. Ask yourself: is enough detail provided to run the same analysis again with the information provided by the user? Be aware for instances where the statistical models appear specific, but actually leave openings for the precise test. See the following examples: 

If someone specifies a 2x3 ANOVA with both factors within subjects, there is still flexibility with the various types of ANOVAs that could be run. Either a repeated measures ANOVA (RMANOVA) or a multivariate ANOVA (MANOVA) could be used for that design, which are two different tests. 
If you are going to perform a sequential analysis and check after 50, 100, and 150 samples, you must also specify the p-values you’ll test against at those three points.
-->

We use the R-package brms to compute a Bayesian ordinal regression model to
predict participants selection of:
  
  - only the non-exhaustive situation (category 1)
  - both, the non-exhaustive and the exhaustive situation (category 2)
  - only the exhaustive situation (category 3)

We use brms default priors except for the slope coefficients for which we use a
wide and uninformative prior: a student-t distribution with 1 degree of freedom,
mean 0 and standard deviation 2.

We consider the main effects of the three predictors 'QUD', 'exh', 'nonExh', the
2-way interactions between 'QUD' and 'exh', and between 'exh' and 'nonExh'
(since for nonExh=internal, we only have QUD='if-p', the 3-way interaction and
the 2-way interaction between  'QUD' and 'nonExh' are not considered). We
include *exh* and *nonExh* as predictors due to our results from Experiment 1,
which make us expect to see a difference in participants' selections depending
on the exact stimulus. Further, we include random intercepts and slopes for each
participant.

In brms:

  * family = cumulative("probit")
  * formula = response ~ 1 + QUD * exh + exh * nonExh + (1 + exh + nonExh + QUD | prolific_id)
  * prior = set_prior("student_t(1, 0, 2)", class = "b")
                       

### 20. Transformations 

<!-- 
If you plan on transforming, centering, recoding the data, or will require a coding scheme for categorical variables, please describe that process.

Example: The “Effect of sugar on brownie tastiness” does not require any additional transformations. However, if it were using a regression analysis and each level of sweet had been categorically described (e.g. not sweet, somewhat sweet, sweet, and very sweet), ‘sweet’ could be dummy coded with ‘not sweet’ as the reference category. 

More information: If any categorical predictors are included in a regression, indicate how those variables will be coded (e.g. dummy coding, summation coding, etc.) and what the reference category will be. 
-->

We will use dummy coding for all three categorical independent variables, the
reference category for 'exhaustive' and 'non-exhaustive' will be withD (with
distractor) and 'ext' (external) respectively (corresponding to stimulus D). The
reference category for 'QUD' will be 'if-p'.

### 21. Inference criteria 

<!-- 
What criteria will you use to make inferences? Please describe the information you will use (e.g. p-values, bayes factors, specific model fit indices), as well as cut-off criterion, where appropriate. Will you be using one or two tailed tests for each of your analyses? If you are comparing multiple conditions or testing multiple hypotheses, will you account for this?

Example: We will use the standard p<.05 criteria for determining if the ANOVA and the post hoc test suggest that the results are significantly different from those expected if the null hypothesis were correct. The post-hoc Tukey-Kramer test adjusts for multiple comparisons. 

More information: P-values, confidence intervals, and effect sizes are standard means for making an inference, and any level is acceptable, though some criteria must be specified in this or previous fields. Bayesian analyses should specify a Bayes factor or a credible interval. If you are selecting models, then how will you determine the relative quality of each? In regards to multiple comparisons, this is a question with few “wrong” answers. In other words, transparency is more important than any specific method of controlling the false discovery rate or false error rate. One may state an intention to report all tests conducted or one may conduct a specific correction procedure; either strategy is acceptable.
-->

To test our main hypothesis, we will check whether the predicted coefficient is
larger when QUD=willq as compared to QUD=ifp, corresponding to a more exhaustive
interpretation of the conditional when QUD=willq. We will use brms' hypothesis
function with the following arguments to test our main hypothesis separately for
the two stimuli for which we have data for both QUD (B+D):
  
  * stimulus D: "QUDwillq > 0"
  * stimulus B: "QUDwillq + exhwoD + QUDwillq:exhwoD > exhwoD" (short "QUDwillq + QUDwillq:exhwoD > 0")

To test whether there is an effect across both stimuli, we will draw samples
from the posterior and check how often the predicted coefficient is larger when
QUD=willq as compared to QUD=ifp, independently of the stimulus.
Similarly, testing H1.1 and H1.2 will also be done based on samples drawn from
the posterior.
We consider the result as strong evidence in favor of our hypotheses if the
respective posterior probability is larger than 0.95.


### 22. Data exclusion 

<!-- 
How will you determine what data or samples, if any, to exclude from your analyses? How will outliers be handled? Will you use any awareness check?

Example: No checks will be performed to determine eligibility for inclusion besides verification that each subject answered each of the three tastiness indices. Outliers will be included in the analysis. 

More information: Any rule for excluding a particular set of data is acceptable. One may describe rules for excluding a participant or for identifying outlier data.
-->

We will exclude all data from from participants who

  * did not select the correct scene in the attention-check trial
  * selected the control scene at least once in the test phase (excluding the 4
  practice trials)
  * affirmed in the questions in the end that they only read Bob's answer or
  that Ann's question was always the same
  * mention something in the comments section in the end that suggests that they
  were not able to conduct the experiment properly.
  * responded within less than 6 seconds in at least 2 of the critical trials


### 23. Missing data

<!-- 
How will you deal with incomplete or missing data?

Example: If a subject does not complete any of the three indices of tastiness, that subject will not be included in the analysis.

More information: Any relevant explanation is acceptable. As a final reminder, remember that the final analysis must follow the specified plan, and deviations must be either strongly justified or included as a separate, exploratory analysis. 
--> 

This not applicable.

### 24. Exploratory analysis

<!-- 
If you plan to explore your data set to look for unexpected differences or relationships, you may describe those tests here. An exploratory test is any test where a prediction is not made up front, or there are multiple possible tests that you are going to use. A statistically significant finding in an exploratory test is a great way to form a new confirmatory hypothesis, which could be registered at a later time. 

Example: We expect that certain demographic traits may be related to taste preferences. Therefore, we will look for relationships between demographic variables (age, gender, income, and marital status) and the primary outcome measures of taste preferences.
-->

1. Besides our main hypotheses formulated above (18. Analysis plan), we will
consider two *stronger versions* of these hypotheses in an exploratory analysis
where we compare the selection rate of only the exhaustive situation vs. both
situations (exh + nonExh) given a fixed QUD:

  - **H2**: P(exh | QUD=will-q) > P(both | QUD=will-q), that is, the selection
  rate of only the exhaustive situation is larger than the selection rate of both,
  the exhaustive and the non-exhaustive situation in trials where QUD=will-q.
  
  - **H3**: P(both | QUD=if-p) >= P(exh | QUD=if-p), that is, the selection rate
  of both, the exhaustive and the non-exhaustive situation, is at least as large
  as the selection rate of only the exhaustive situation in trials where QUD=if-p.

2. Further, we may explore participants' Reaction times. We will check
whether there are salient differences in participants' reaction times between
the different stimuli and QUDs.

3. Since in Experiment 1 many participants gave the same answer independent of
the QUD, we will check how often this happens in this experiment as well and we
will possibly repeat the analysis for stimuli B+D with only data from trials
where participants gave different answers when QUD=if-p and when QUD=will-q.


### 25. Other 

<!-- 
If there is any additional information that you feel needs to be included in your preregistration, please enter it here. Literature cited, disclosures of any related work such as replications or work that uses the same data, or other context that will be helpful for future readers would be appropriate here. 
-->

Link to anonymous OSF repository containing all code:

[https://osf.io/sjdax/?view_only=1b796a24aec8428cb70a4abf48efcae2](https://osf.io/sjdax/?view_only=1b796a24aec8428cb70a4abf48efcae2)

## References 

Kai Von Fintel, “Conditional Strengthening,” Unpublished Manuscript, 2001.


